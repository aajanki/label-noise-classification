{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pystan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='white', font_scale=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris['data'], iris['target'], test_size=0.3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=iris['feature_names'])\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=iris['feature_names'])\n",
    "\n",
    "print(f'Train sample dim: {X_train.shape}')\n",
    "print(f'Train class proportions: {iris[\"target_names\"][0]}: {(y_train == 0).mean():.2f}, {iris[\"target_names\"][1]}: {(y_train == 1).mean():.2f}, {iris[\"target_names\"][2]}: {(y_train == 2).mean():.2f}')\n",
    "print(f'Test samples: {len(y_test)}')\n",
    "print(f'Train class proportions: {iris[\"target_names\"][0]}: {(y_test == 0).mean():.2f}, {iris[\"target_names\"][1]}: {(y_test == 1).mean():.2f}, {iris[\"target_names\"][2]}: {(y_test == 2).mean():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=10)\n",
    "logreg.fit(X_train, y_train)\n",
    "ypred_train = logreg.predict(X_train)\n",
    "ypred_test = logreg.predict(X_test)\n",
    "\n",
    "print(f'intercept = {logreg.intercept_}')\n",
    "print(f'beta = {logreg.coef_}')\n",
    "\n",
    "print()\n",
    "print('Train')\n",
    "print(classification_report(y_train, ypred_train, target_names=iris['target_names']))\n",
    "\n",
    "print()\n",
    "print('Test')\n",
    "print(classification_report(y_test, ypred_test, target_names=iris['target_names']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StanClassifierWrapper():\n",
    "    def __init__(self, stan_model, prior_sigma=1, transition_prior=1, restarts=1):\n",
    "        self.sm = stan_model\n",
    "        self.intercept_ = None\n",
    "        self.coef_ = None\n",
    "        self.gamma_ = None\n",
    "        self.prior_sigma = prior_sigma\n",
    "        self.transition_prior = transition_prior\n",
    "        self.restarts = restarts\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        K = len(np.unique(y))\n",
    "        data = {\n",
    "            'N': X.shape[0],\n",
    "            'D': X.shape[1],\n",
    "            'K': K,\n",
    "            'X': X,\n",
    "            'y': y + 1,\n",
    "            'prior_sigma': self.prior_sigma,\n",
    "            'transition_prior': self.transition_prior\n",
    "        }\n",
    "        \n",
    "        best_par = None\n",
    "        best_lp = None\n",
    "        for _ in range(max(self.restarts, 1)):\n",
    "            res = sm.optimizing(data=data, init=self.param_initializer(K, X.shape[1]), as_vector=False)\n",
    "            if best_lp is None or res['value'] > best_lp:\n",
    "                best_par = res['par']\n",
    "                best_lp = res['value']\n",
    "            \n",
    "        self.intercept_ = best_par['alpha']\n",
    "        self.coef_ = best_par['beta'].T\n",
    "        if 'gamma' in best_par:\n",
    "            self.gamma_ = best_par['gamma']\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.asarray((self.intercept_ + X.dot(self.coef_.T)).idxmax(axis=1))\n",
    "    \n",
    "    def param_initializer(self, num_classes, num_features):\n",
    "        def wrapped():\n",
    "            ginit = 0.01/(num_classes-1)*np.ones((num_classes, num_classes))\n",
    "            np.fill_diagonal(ginit, 0.99)\n",
    "            return {\n",
    "                'alpha': np.random.uniform(-2, 2, num_classes),\n",
    "                'beta': np.random.uniform(-2, 2, (num_features, num_classes)),\n",
    "                'gamma': ginit\n",
    "            }\n",
    "        \n",
    "        return wrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_code = \"\"\"\n",
    "data {\n",
    "    int<lower=0> N;  // number of observations\n",
    "    int<lower=1> D;  // number of predictors\n",
    "    int<lower=2> K;  // number of classes\n",
    "    matrix[N, D] X;\n",
    "    int<lower=1,upper=K> y[N];  // observed (noisy) class labels\n",
    "    real prior_sigma;\n",
    "    real transition_prior;\n",
    "}\n",
    "parameters {\n",
    "    vector[K] alpha;\n",
    "    matrix[D, K] beta;\n",
    "    simplex[K] gamma[K];\n",
    "}\n",
    "model {\n",
    "    matrix[N, K] x_beta = rep_matrix(to_row_vector(alpha), N) + X * beta;\n",
    "    \n",
    "    alpha ~ normal(0, prior_sigma);\n",
    "    to_vector(beta) ~ normal(0, prior_sigma);\n",
    "    for (i in 1:K) {\n",
    "        gamma[i] ~ dirichlet(rep_vector(transition_prior, K));\n",
    "    }\n",
    "\n",
    "    for (n in 1:N) {\n",
    "        vector[K] u = rep_vector(0.0, K);\n",
    "        vector[K] w = softmax(x_beta[n]');\n",
    "        \n",
    "        for (j in 1:K) {\n",
    "            u += w[j] * gamma[j];\n",
    "        }\n",
    "                \n",
    "        y[n] ~ categorical(u);\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "sm = pystan.StanModel(model_code=robust_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = StanClassifierWrapper(sm, prior_sigma=10, transition_prior=2, restarts=6)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "ypred_train = clf.predict(X_train)\n",
    "ypred_test = clf.predict(X_test)\n",
    "\n",
    "print(f'intercept = {clf.intercept_}')\n",
    "print(f'beta = {clf.coef_}')\n",
    "print(f'gamma = {clf.gamma_}')\n",
    "\n",
    "print()\n",
    "print('Train')\n",
    "print(classification_report(y_train, ypred_train, target_names=iris['target_names']))\n",
    "\n",
    "print()\n",
    "print('Test')\n",
    "print(classification_report(y_test, ypred_test, target_names=iris['target_names']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_transition_prob(size):\n",
    "    U = np.zeros([size, size])\n",
    "    for i in range(size):\n",
    "        ind = [x for x in range(size) if x != i]\n",
    "        U[i, ind] = np.random.dirichlet(0.5*np.ones(size - 1))\n",
    "    return U\n",
    "\n",
    "def draw_noisy_labels(y_true, noise_prob, transition_prob):\n",
    "    K = transition_prob.shape[0]\n",
    "    N = len(y_true)\n",
    "\n",
    "    y_noisy = np.array(y_true)\n",
    "    for i in np.random.choice(N, size=int(noise_prob*N), replace=False):\n",
    "        y_noisy[i] = np.random.choice(range(K), p=transition_prob[y_true[i], :])\n",
    "\n",
    "    return y_noisy\n",
    "\n",
    "def eval_test_error(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    ypred = clf.predict(X_test)\n",
    "    return 1 - accuracy_score(y_test, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repeats = 40\n",
    "noise_proportions = np.array([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6])\n",
    "\n",
    "errors = []\n",
    "for i, flip_prob in enumerate(noise_proportions):\n",
    "    scores = []\n",
    "    for _ in range(n_repeats):\n",
    "        T = draw_transition_prob(3)\n",
    "        y_noisy = draw_noisy_labels(y_train, flip_prob, T)\n",
    "        noise_level = 1.0 - (y_noisy == y_train).mean()\n",
    "\n",
    "        robust = StanClassifierWrapper(sm, prior_sigma=10, transition_prior=2, restarts=6)\n",
    "        r_err = eval_test_error(robust, X_train, y_noisy, X_test, y_test)\n",
    "        errors.append({\n",
    "            'Model': 'Robust regression',\n",
    "            'Noise level (%)': 100*noise_level,\n",
    "            'Test error (%)': 100*r_err\n",
    "        })\n",
    "        \n",
    "        logreg = LogisticRegression(C=10)\n",
    "        r_err = eval_test_error(logreg, X_train, y_noisy, X_test, y_test)\n",
    "        errors.append({\n",
    "            'Model': 'Logistic regression',\n",
    "            'Noise level (%)': 100*noise_level,\n",
    "            'Test error (%)': 100*r_err\n",
    "        })\n",
    "\n",
    "errors = pd.DataFrame(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='Noise level (%)', y='Test error (%)', hue='Model', kind='line', data=errors, height=6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
